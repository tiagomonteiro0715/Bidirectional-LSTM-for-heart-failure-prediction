{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000f3634-d1ea-4a73-a661-99bef08b8935",
   "metadata": {},
   "source": [
    "## A melhorar antes de mandar ao professor daniel\n",
    "\n",
    "F1 score - https://torchmetrics.readthedocs.io/en/stable/classification/f1_score.html\n",
    "\n",
    "ter resto das capacidades de PyTorch lightning\n",
    "\n",
    "dividir em deve test ainda para comparar melhor\n",
    "\n",
    "Documentar tudo melhor\n",
    "\n",
    "### Ver minhas notas para ver o que mais se pode mudar\n",
    "\n",
    "https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction\n",
    "\n",
    "init.xavier_uniform_(self.lstm.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece2955f-b947-434f-bc85-487ae2784f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b101c6-a7aa-4f02-802d-711449cb209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available CPUs: 8\n",
      "Number of available GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "num_cores_os = os.cpu_count()\n",
    "print(f\"Number of available CPUs: {num_cores_os}\")\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs and store it in a variable\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "else:\n",
    "    num_gpus = 0  # No GPUs available\n",
    "\n",
    "print(f\"Number of available GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1cb88fb-b10f-4ba5-866b-f3a5f19139eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n",
      "0     40   M           ATA        140          289          0     Normal   \n",
      "1     49   F           NAP        160          180          0     Normal   \n",
      "2     37   M           ATA        130          283          0         ST   \n",
      "3     48   F           ASY        138          214          0     Normal   \n",
      "4     54   M           NAP        150          195          0     Normal   \n",
      "..   ...  ..           ...        ...          ...        ...        ...   \n",
      "913   45   M            TA        110          264          0     Normal   \n",
      "914   68   M           ASY        144          193          1     Normal   \n",
      "915   57   M           ASY        130          131          0     Normal   \n",
      "916   57   F           ATA        130          236          0        LVH   \n",
      "917   38   M           NAP        138          175          0     Normal   \n",
      "\n",
      "     MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
      "0      172              N      0.0       Up             0  \n",
      "1      156              N      1.0     Flat             1  \n",
      "2       98              N      0.0       Up             0  \n",
      "3      108              Y      1.5     Flat             1  \n",
      "4      122              N      0.0       Up             0  \n",
      "..     ...            ...      ...      ...           ...  \n",
      "913    132              N      1.2     Flat             1  \n",
      "914    141              N      3.4     Flat             1  \n",
      "915    115              Y      1.2     Flat             1  \n",
      "916    174              N      0.0     Flat             1  \n",
      "917    173              N      0.0       Up             0  \n",
      "\n",
      "[918 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset, assuming it's in a CSV file\n",
    "df = pd.read_csv('heart.xls')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "033a2423-7c23-4b2a-9e0d-16dd171dbd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
      "0     40    1              1        140          289          0           1   \n",
      "1     49    0              2        160          180          0           1   \n",
      "2     37    1              1        130          283          0           2   \n",
      "3     48    0              0        138          214          0           1   \n",
      "4     54    1              2        150          195          0           1   \n",
      "..   ...  ...            ...        ...          ...        ...         ...   \n",
      "913   45    1              3        110          264          0           1   \n",
      "914   68    1              0        144          193          1           1   \n",
      "915   57    1              0        130          131          0           1   \n",
      "916   57    0              1        130          236          0           0   \n",
      "917   38    1              2        138          175          0           1   \n",
      "\n",
      "     MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
      "0      172               0      0.0         2             0  \n",
      "1      156               0      1.0         1             1  \n",
      "2       98               0      0.0         2             0  \n",
      "3      108               1      1.5         1             1  \n",
      "4      122               0      0.0         2             0  \n",
      "..     ...             ...      ...       ...           ...  \n",
      "913    132               0      1.2         1             1  \n",
      "914    141               0      3.4         1             1  \n",
      "915    115               1      1.2         1             1  \n",
      "916    174               0      0.0         1             1  \n",
      "917    173               0      0.0         2             0  \n",
      "\n",
      "[918 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "encoder = LabelEncoder()\n",
    "categorical_cols = [\"Sex\", \"ChestPainType\", \"RestingECG\", \"ExerciseAngina\", \"ST_Slope\"]\n",
    "for col in categorical_cols:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af455e8-85f7-4c95-8abd-e49d0a19d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40.   1.   1.  ...  0.   0.   2. ]\n",
      " [49.   0.   2.  ...  0.   1.   1. ]\n",
      " [37.   1.   1.  ...  0.   0.   2. ]\n",
      " ...\n",
      " [57.   1.   0.  ...  1.   1.2  1. ]\n",
      " [57.   0.   1.  ...  0.   0.   1. ]\n",
      " [38.   1.   2.  ...  0.   0.   2. ]]\n"
     ]
    }
   ],
   "source": [
    "features = df.drop('HeartDisease', axis=1).values\n",
    "target = df['HeartDisease'].values\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cfc797-9284-4b1c-8c8f-cc1084f7d9de",
   "metadata": {},
   "source": [
    "# Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbc5a2c-c9f4-49d0-9ead-405145283c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.4331398   0.51595242  0.22903206 ... -0.8235563  -0.83243239\n",
      "   1.05211381]\n",
      " [-0.47848359 -1.93816322  1.27505906 ... -0.8235563   0.10566353\n",
      "  -0.59607813]\n",
      " [-1.75135854  0.51595242  0.22903206 ... -0.8235563  -0.83243239\n",
      "   1.05211381]\n",
      " ...\n",
      " [ 0.37009972  0.51595242 -0.81699495 ...  1.21424608  0.29328271\n",
      "  -0.59607813]\n",
      " [ 0.37009972 -1.93816322  0.22903206 ... -0.8235563  -0.83243239\n",
      "  -0.59607813]\n",
      " [-1.64528563  0.51595242  1.27505906 ... -0.8235563  -0.83243239\n",
      "   1.05211381]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2007280-6db8-412f-93c7-0700eefda72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and target to NumPy arrays\n",
    "X = np.array(features, dtype=np.float32)\n",
    "y = np.array(target, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b32c3af-9231-47f5-92eb-8f8d9c632e18",
   "metadata": {},
   "source": [
    "# Converter isto para um bom texto pequeno\n",
    "\n",
    "LSTM models require input data to be three-dimensional, with the dimensions representing (batch size, time_steps, and features) - ver como preparar informação para isto\n",
    "\n",
    "Batch size - rows\n",
    "\n",
    "time_steps - collums\n",
    "\n",
    "features - number of matrixes\n",
    "\n",
    "(918 - 1 - 11)\n",
    "\n",
    "(batch_size, seq_len, input_size)\n",
    "\n",
    "(numero de pacienctes - numero de pacientes a processar de cada vez no LSTM - numero de features)\n",
    "\n",
    "## Não é uma matriz\n",
    "\n",
    "É uma especificação de como o LSTM deve processar a informação\n",
    "\n",
    "Neste caso:\n",
    "918 is the number of pacients\n",
    "1 is how many pacients to process \n",
    "11 how many featrues I am processing on each pacient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d3ade47-373b-401e-8d93-0dc90bc257de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (918, 1, 11))\n",
    "y = np.reshape(y, (918, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6e4b45a-5941-4741-bf68-1060d63179b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and devidation sets\n",
    "X_train, X_dev_and_test, y_train, y_dev_and_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_dev_and_test, y_dev_and_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31fbd79c-4ade-4fad-b894-fec59f22d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "input_dim=11\n",
    "hidden_dim=1\n",
    "num_layers=1\n",
    "output_dim=1\n",
    "\n",
    "batch_size=64\n",
    "num_classes=2\n",
    "\n",
    "features = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b21cb40-7517-4db8-9840-05927d535f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([550, 1, 11])\n",
      "torch.Size([550, 1])\n",
      "torch.Size([184, 1, 11])\n",
      "torch.Size([184, 1])\n",
      "torch.Size([184, 1, 11])\n",
      "torch.Size([184, 1])\n"
     ]
    }
   ],
   "source": [
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train).clone().detach()\n",
    "y_train = torch.tensor(y_train).clone().detach()\n",
    "\n",
    "X_dev = torch.tensor(X_dev).clone().detach()\n",
    "y_dev = torch.tensor(y_dev).clone().detach()\n",
    "\n",
    "\n",
    "X_test = torch.tensor(X_test).clone().detach()\n",
    "y_test = torch.tensor(y_test).clone().detach()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ab98a30-7987-4955-bf15-eafd24f3b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeartPredictionModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(HeartPredictionModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        #init.xavier_uniform_(self.lstm.weight)\n",
    "        self.fc = nn.Linear(2* hidden_dim, output_dim) \n",
    "        init.xavier_uniform_(self.fc.weight)\n",
    "        self.sigmoid = nn.Sigmoid()  # Add a sigmoid activation function\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # Get the last output from the sequence for each batch\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)  # Apply sigmoid activation\n",
    "        return out \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "        return [optimizer], [scheduler]\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.BCELoss()(outputs, targets)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.BCELoss()(outputs, targets)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = TensorDataset(X_train, y_train)\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=num_cores_os)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = TensorDataset(X_dev, y_dev)\n",
    "        return DataLoader(dataset, batch_size=batch_size, drop_last=True, num_workers=num_cores_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03a05719-dc80-4042-be3d-0e2a7a87a0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | lstm    | LSTM    | 112   \n",
      "1 | fc      | Linear  | 3     \n",
      "2 | sigmoid | Sigmoid | 0     \n",
      "------------------------------------\n",
      "115       Trainable params\n",
      "0         Non-trainable params\n",
      "115       Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba38c6143a94d77b205379e0f55a41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    }
   ],
   "source": [
    "model = HeartPredictionModel(input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, output_dim=output_dim)\n",
    "\n",
    "# Initialize a PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(max_epochs=10)  # Set the number of epochs and GPU usage as needed\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84ccb3-c9a3-4f94-a994-a035d88235cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearningKernel",
   "language": "python",
   "name": "envi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
