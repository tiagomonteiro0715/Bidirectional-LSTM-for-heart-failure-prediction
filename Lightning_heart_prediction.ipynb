{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fbd79c-4ade-4fad-b894-fec59f22d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "learning_rate=0.001\n",
    "hidden_dim=32\n",
    "num_layers=5\n",
    "\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "\n",
    "val_error = 123456789\n",
    "#Hyperparameters\n",
    "input_dim=11\n",
    "output_dim=1\n",
    "\n",
    "first_fc_layer = 100\n",
    "second_fc_layer = 20\n",
    " \n",
    "lstm_dropout = 0.4\n",
    "dropout_prob = 0.3\n",
    "\n",
    "num_classes=2\n",
    "\n",
    "features = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f3634-d1ea-4a73-a661-99bef08b8935",
   "metadata": {},
   "source": [
    "## A melhorar antes de mandar ao professor daniel\n",
    "\n",
    "F1 score - https://torchmetrics.readthedocs.io/en/stable/classification/f1_score.html\n",
    "\n",
    "ter resto das capacidades de PyTorch lightning\n",
    "\n",
    "dividir em deve test ainda para comparar melhor\n",
    "\n",
    "Documentar tudo melhor\n",
    "\n",
    "Fazer ainda função que, dos casos testes da vida real, testa quantos é que acerta e a média destes e tudo o mais\n",
    "\n",
    "### Ver minhas notas para ver o que mais se pode mudar\n",
    "\n",
    "https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction\n",
    "\n",
    "init.xavier_uniform_(self.lstm.weight)\n",
    "\n",
    "mistakes and secret things one can do in PyTorch lightning to make better AI models\n",
    "\n",
    "Usar matplotlib e outros graficos para isto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece2955f-b947-434f-bc85-487ae2784f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b101c6-a7aa-4f02-802d-711449cb209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available CPUs: 8\n",
      "Number of available GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "num_cores_os = os.cpu_count()\n",
    "print(f\"Number of available CPUs: {num_cores_os}\")\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs and store it in a variable\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "else:\n",
    "    num_gpus = 0  # No GPUs available\n",
    "\n",
    "print(f\"Number of available GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1cb88fb-b10f-4ba5-866b-f3a5f19139eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n",
      "0     40   M           ATA        140          289          0     Normal   \n",
      "1     49   F           NAP        160          180          0     Normal   \n",
      "2     37   M           ATA        130          283          0         ST   \n",
      "3     48   F           ASY        138          214          0     Normal   \n",
      "4     54   M           NAP        150          195          0     Normal   \n",
      "..   ...  ..           ...        ...          ...        ...        ...   \n",
      "913   45   M            TA        110          264          0     Normal   \n",
      "914   68   M           ASY        144          193          1     Normal   \n",
      "915   57   M           ASY        130          131          0     Normal   \n",
      "916   57   F           ATA        130          236          0        LVH   \n",
      "917   38   M           NAP        138          175          0     Normal   \n",
      "\n",
      "     MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
      "0      172              N      0.0       Up             0  \n",
      "1      156              N      1.0     Flat             1  \n",
      "2       98              N      0.0       Up             0  \n",
      "3      108              Y      1.5     Flat             1  \n",
      "4      122              N      0.0       Up             0  \n",
      "..     ...            ...      ...      ...           ...  \n",
      "913    132              N      1.2     Flat             1  \n",
      "914    141              N      3.4     Flat             1  \n",
      "915    115              Y      1.2     Flat             1  \n",
      "916    174              N      0.0     Flat             1  \n",
      "917    173              N      0.0       Up             0  \n",
      "\n",
      "[918 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset, assuming it's in a CSV file\n",
    "df = pd.read_csv('heart.xls')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033a2423-7c23-4b2a-9e0d-16dd171dbd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
      "0     40    1              1        140          289          0           1   \n",
      "1     49    0              2        160          180          0           1   \n",
      "2     37    1              1        130          283          0           2   \n",
      "3     48    0              0        138          214          0           1   \n",
      "4     54    1              2        150          195          0           1   \n",
      "..   ...  ...            ...        ...          ...        ...         ...   \n",
      "913   45    1              3        110          264          0           1   \n",
      "914   68    1              0        144          193          1           1   \n",
      "915   57    1              0        130          131          0           1   \n",
      "916   57    0              1        130          236          0           0   \n",
      "917   38    1              2        138          175          0           1   \n",
      "\n",
      "     MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
      "0      172               0      0.0         2             0  \n",
      "1      156               0      1.0         1             1  \n",
      "2       98               0      0.0         2             0  \n",
      "3      108               1      1.5         1             1  \n",
      "4      122               0      0.0         2             0  \n",
      "..     ...             ...      ...       ...           ...  \n",
      "913    132               0      1.2         1             1  \n",
      "914    141               0      3.4         1             1  \n",
      "915    115               1      1.2         1             1  \n",
      "916    174               0      0.0         1             1  \n",
      "917    173               0      0.0         2             0  \n",
      "\n",
      "[918 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "encoder = LabelEncoder()\n",
    "categorical_cols = [\"Sex\", \"ChestPainType\", \"RestingECG\", \"ExerciseAngina\", \"ST_Slope\"]\n",
    "for col in categorical_cols:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5af455e8-85f7-4c95-8abd-e49d0a19d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40.   1.   1.  ...  0.   0.   2. ]\n",
      " [49.   0.   2.  ...  0.   1.   1. ]\n",
      " [37.   1.   1.  ...  0.   0.   2. ]\n",
      " ...\n",
      " [57.   1.   0.  ...  1.   1.2  1. ]\n",
      " [57.   0.   1.  ...  0.   0.   1. ]\n",
      " [38.   1.   2.  ...  0.   0.   2. ]]\n"
     ]
    }
   ],
   "source": [
    "features = df.drop('HeartDisease', axis=1).values\n",
    "target = df['HeartDisease'].values\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cfc797-9284-4b1c-8c8f-cc1084f7d9de",
   "metadata": {},
   "source": [
    "# Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fbc5a2c-c9f4-49d0-9ead-405145283c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.4331398   0.51595242  0.22903206 ... -0.8235563  -0.83243239\n",
      "   1.05211381]\n",
      " [-0.47848359 -1.93816322  1.27505906 ... -0.8235563   0.10566353\n",
      "  -0.59607813]\n",
      " [-1.75135854  0.51595242  0.22903206 ... -0.8235563  -0.83243239\n",
      "   1.05211381]\n",
      " ...\n",
      " [ 0.37009972  0.51595242 -0.81699495 ...  1.21424608  0.29328271\n",
      "  -0.59607813]\n",
      " [ 0.37009972 -1.93816322  0.22903206 ... -0.8235563  -0.83243239\n",
      "  -0.59607813]\n",
      " [-1.64528563  0.51595242  1.27505906 ... -0.8235563  -0.83243239\n",
      "   1.05211381]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2007280-6db8-412f-93c7-0700eefda72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and target to NumPy arrays\n",
    "X = np.array(features, dtype=np.float32)\n",
    "y = np.array(target, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b32c3af-9231-47f5-92eb-8f8d9c632e18",
   "metadata": {},
   "source": [
    "# Converter isto para um bom texto pequeno\n",
    "\n",
    "LSTM models require input data to be three-dimensional, with the dimensions representing (batch size, time_steps, and features) - ver como preparar informação para isto\n",
    "\n",
    "Batch size - rows\n",
    "\n",
    "time_steps - collums\n",
    "\n",
    "features - number of matrixes\n",
    "\n",
    "(918 - 1 - 11)\n",
    "\n",
    "(batch_size, seq_len, input_size)\n",
    "\n",
    "(numero de pacienctes - numero de pacientes a processar de cada vez no LSTM - numero de features)\n",
    "\n",
    "## Não é uma matriz\n",
    "\n",
    "É uma especificação de como o LSTM deve processar a informação\n",
    "\n",
    "Neste caso:\n",
    "918 is the number of pacients\n",
    "1 is how many pacients to process \n",
    "11 how many featrues I am processing on each pacient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d3ade47-373b-401e-8d93-0dc90bc257de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.4331398   0.5159524   0.22903205 ... -0.8235563  -0.8324324\n",
      "    1.0521138 ]]\n",
      "\n",
      " [[-0.4784836  -1.9381633   1.2750591  ... -0.8235563   0.10566353\n",
      "   -0.59607816]]\n",
      "\n",
      " [[-1.7513585   0.5159524   0.22903205 ... -0.8235563  -0.8324324\n",
      "    1.0521138 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.37009972  0.5159524  -0.81699497 ...  1.214246    0.29328272\n",
      "   -0.59607816]]\n",
      "\n",
      " [[ 0.37009972 -1.9381633   0.22903205 ... -0.8235563  -0.8324324\n",
      "   -0.59607816]]\n",
      "\n",
      " [[-1.6452856   0.5159524   1.2750591  ... -0.8235563  -0.8324324\n",
      "    1.0521138 ]]]\n",
      "(918, 1, 11)\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X, (918, 1, 11))\n",
    "\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "945e3d63-d7b5-490e-b2f3-0d579a585f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(918, 1)\n"
     ]
    }
   ],
   "source": [
    "y = np.reshape(y, (918, 1))\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e4b45a-5941-4741-bf68-1060d63179b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and devidation sets\n",
    "X_train, X_dev_and_test, y_train, y_dev_and_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_dev_and_test, y_dev_and_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b21cb40-7517-4db8-9840-05927d535f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([550, 1, 11])\n",
      "torch.Size([550, 1])\n",
      "torch.Size([184, 1, 11])\n",
      "torch.Size([184, 1])\n",
      "torch.Size([184, 1, 11])\n",
      "torch.Size([184, 1])\n"
     ]
    }
   ],
   "source": [
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train).clone().detach()\n",
    "y_train = torch.tensor(y_train).clone().detach()\n",
    "\n",
    "X_dev = torch.tensor(X_dev).clone().detach()\n",
    "y_dev = torch.tensor(y_dev).clone().detach()\n",
    "\n",
    "\n",
    "X_test = torch.tensor(X_test).clone().detach()\n",
    "y_test = torch.tensor(y_test).clone().detach()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ab98a30-7987-4955-bf15-eafd24f3b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeartPredictionModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(HeartPredictionModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True, dropout=lstm_dropout)\n",
    "        #init.xavier_uniform_(self.lstm.weight)\n",
    "                \n",
    "        self.fc1 = nn.Linear(2* hidden_dim, first_fc_layer) \n",
    "        init.xavier_uniform_(self.fc1.weight)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Add dropout layer\n",
    "        \n",
    "        self.fc2 = nn.Linear(first_fc_layer, second_fc_layer) \n",
    "        init.xavier_uniform_(self.fc2.weight)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Add dropout layer\n",
    "\n",
    "        self.fc3 = nn.Linear(second_fc_layer, output_dim) \n",
    "        init.xavier_uniform_(self.fc3.weight)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()  # Add a sigmoid activation function\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # Get the last output from the sequence for each batch\n",
    "        out = self.dropout(out)  # Apply dropout\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout(out)  # Apply dropout\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)  # Apply dropout\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)  # Apply sigmoid activation\n",
    "\n",
    "        return out \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "        return [optimizer], [scheduler]\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.BCELoss()(outputs, targets)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.BCELoss()(outputs, targets)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        val_error = loss\n",
    "        return loss\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = TensorDataset(X_train, y_train)\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=num_cores_os)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = TensorDataset(X_dev, y_dev)\n",
    "        return DataLoader(dataset, batch_size=batch_size, drop_last=True, num_workers=num_cores_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03a05719-dc80-4042-be3d-0e2a7a87a0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-10-09 19:20:22.566566: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-09 19:20:22.566614: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-09 19:20:22.566643: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-09 19:20:22.574034: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-09 19:20:23.858903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | lstm    | LSTM    | 111 K \n",
      "1 | fc1     | Linear  | 6.5 K \n",
      "2 | dropout | Dropout | 0     \n",
      "3 | fc2     | Linear  | 2.0 K \n",
      "4 | fc3     | Linear  | 21    \n",
      "5 | sigmoid | Sigmoid | 0     \n",
      "------------------------------------\n",
      "120 K     Trainable params\n",
      "0         Non-trainable params\n",
      "120 K     Total params\n",
      "0.482     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drifter/projects/ai/myenv/lib64/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57af3228ce424a29a747bffc0130b098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "model = HeartPredictionModel(input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, output_dim=output_dim)\n",
    "\n",
    "# Initialize a PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(max_epochs=num_epochs)  # Set the number of epochs and GPU usage as needed\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85403faf-487a-4c0f-8506-44e7bd80310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
